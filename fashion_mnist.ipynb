{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAAVqdcvgiLX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from torchview import draw_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install torchview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ4BUQ10pM-j",
        "outputId": "386eadab-112b-4450-991b-93c7e179fd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchview\n",
            "  Downloading torchview-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from torchview) (0.21)\n",
            "Downloading torchview-0.2.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "f-oDvbvKSDzv",
        "outputId": "c1509974-6240-48ff-beed-630efa21feec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be466d13-ffa4-49a3-812e-b98408bdd681\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be466d13-ffa4-49a3-812e-b98408bdd681\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fashion-mnist_test.csv to fashion-mnist_test.csv\n"
          ]
        }
      ],
      "source": [
        "upl = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk-j8bE1ldlZ"
      },
      "outputs": [],
      "source": [
        "d = pd.read_csv('fashion-mnist_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "7wR86nAqljto",
        "outputId": "df30ee71-39cf-4346-bffd-e959f4626edf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0         0       0       0       0       0       0       0       0       9   \n",
              "1         1       0       0       0       0       0       0       0       0   \n",
              "2         2       0       0       0       0       0       0      14      53   \n",
              "3         2       0       0       0       0       0       0       0       0   \n",
              "4         3       0       0       0       0       0       0       0       0   \n",
              "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "9995      0       0       0       0       0       0       0       0       0   \n",
              "9996      6       0       0       0       0       0       0       0       0   \n",
              "9997      8       0       0       0       0       0       0       0       0   \n",
              "9998      8       0       1       3       0       0       0       0       0   \n",
              "9999      1       0       0       0       0       0       0       0     140   \n",
              "\n",
              "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0          8  ...       103        87        56         0         0         0   \n",
              "1          0  ...        34         0         0         0         0         0   \n",
              "2         99  ...         0         0         0         0        63        53   \n",
              "3          0  ...       137       126       140         0       133       224   \n",
              "4          0  ...         0         0         0         0         0         0   \n",
              "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
              "9995       0  ...        32        23        14        20         0         0   \n",
              "9996       0  ...         0         0         0         2        52        23   \n",
              "9997       0  ...       175       172       172       182       199       222   \n",
              "9998       0  ...         0         0         0         0         0         1   \n",
              "9999     119  ...       111        95        75        44         1         0   \n",
              "\n",
              "      pixel781  pixel782  pixel783  pixel784  \n",
              "0            0         0         0         0  \n",
              "1            0         0         0         0  \n",
              "2           31         0         0         0  \n",
              "3          222        56         0         0  \n",
              "4            0         0         0         0  \n",
              "...        ...       ...       ...       ...  \n",
              "9995         1         0         0         0  \n",
              "9996        28         0         0         0  \n",
              "9997        42         0         1         0  \n",
              "9998         0         0         0         0  \n",
              "9999         0         0         0         0  \n",
              "\n",
              "[10000 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-961a8f6a-a452-4cd6-a4f0-0b5ba9dab82b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>175</td>\n",
              "      <td>172</td>\n",
              "      <td>172</td>\n",
              "      <td>182</td>\n",
              "      <td>199</td>\n",
              "      <td>222</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>111</td>\n",
              "      <td>95</td>\n",
              "      <td>75</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-961a8f6a-a452-4cd6-a4f0-0b5ba9dab82b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-961a8f6a-a452-4cd6-a4f0-0b5ba9dab82b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-961a8f6a-a452-4cd6-a4f0-0b5ba9dab82b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0331dadc-3a3a-46b6-b1cb-121e41e66808\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0331dadc-3a3a-46b6-b1cb-121e41e66808')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0331dadc-3a3a-46b6-b1cb-121e41e66808 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_656fe27d-ada0-4601-8655-9b91691ba6a3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('d')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_656fe27d-ada0-4601-8655-9b91691ba6a3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('d');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "d"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTKFLKJBlnH0"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh5bLnO8lp9R"
      },
      "outputs": [],
      "source": [
        "X = d.drop(columns='label').to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dA6bDD7lyJE"
      },
      "outputs": [],
      "source": [
        "y = d['label'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTtBk3xFFZD3"
      },
      "outputs": [],
      "source": [
        "X = X/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNOlLFr-lzjr"
      },
      "outputs": [],
      "source": [
        "Xt,yt = torch.tensor(X,dtype=torch.float),torch.tensor(y,dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5d1hWXyl-Zq",
        "outputId": "69dd98d2-4e66-4505-b125-b9f9f9f5e80a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000, 784])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Xt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMAejpdcmLf8"
      },
      "outputs": [],
      "source": [
        "X_train,X_test = Xt[:4800],Xt[4800:6000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vECAJcabmWM2"
      },
      "outputs": [],
      "source": [
        "Y_train,Y_test = yt[:4800],yt[4800:6000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuge7vqWmfcv",
        "outputId": "87745de0-6577-41c1-83c7-1312027ec96d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4800, 784])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmffR-mNmg8d",
        "outputId": "ea536387-3730-406f-db1c-af3b3340dcd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1200])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDgUeSIYmy4o"
      },
      "outputs": [],
      "source": [
        "class Customdata(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.features = X\n",
        "    self.labels = y\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  def __getitem__(self,index):\n",
        "    return self.features[index],self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aaupb3AnxQg"
      },
      "outputs": [],
      "source": [
        "train_dataset = Customdata(X_train,Y_train)\n",
        "test_dataset = Customdata(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJDgnsMfoW8Z"
      },
      "outputs": [],
      "source": [
        "train_load = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_load = DataLoader(test_dataset,batch_size=32,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlBGLQbjopLI"
      },
      "outputs": [],
      "source": [
        "class NetsMan(nn.Module):\n",
        "  def __init__(self,input_s,output_s,hidden_layers,num_neurons):\n",
        "    super().__init__()\n",
        "    layers = [ nn.Linear(in_features=input_s,out_features=num_neurons),\n",
        "              nn.ReLU()]\n",
        "    for i in range(hidden_layers):\n",
        "      layers.append(\n",
        "          nn.Linear(in_features=num_neurons,out_features=num_neurons)\n",
        "      )\n",
        "      layers.append(nn.ReLU())\n",
        "    layers.append(\n",
        "        nn.Linear(in_features=num_neurons,out_features=output_s)\n",
        "    )\n",
        "\n",
        "\n",
        "    self.network = nn.Sequential(*layers)\n",
        "  def forward(self,x):\n",
        "    return self.network(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjNyMYOdA4WG"
      },
      "outputs": [],
      "source": [
        "Fn = NetsMan(784,10,2,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMudmKTDAsLS"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIXLCEV8AvVq"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(Fn.parameters(),lr=0.1,weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dt42Qi-BlHE",
        "outputId": "99c269ec-48e4-4e5e-ea91-5fb5da0fb5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average loss in 0th itertaion 1.67655552983284\n",
            "average loss in 1th itertaion 0.9294880819320679\n",
            "average loss in 2th itertaion 0.73940884967645\n",
            "average loss in 3th itertaion 0.629139188726743\n",
            "average loss in 4th itertaion 0.5837561628222465\n",
            "average loss in 5th itertaion 0.5454324527581533\n",
            "average loss in 6th itertaion 0.4905869809786479\n",
            "average loss in 7th itertaion 0.48406434764464695\n",
            "average loss in 8th itertaion 0.45143568883339563\n",
            "average loss in 9th itertaion 0.4361442796389262\n",
            "average loss in 10th itertaion 0.4132527248064677\n",
            "average loss in 11th itertaion 0.3989364778995514\n",
            "average loss in 12th itertaion 0.3827416069805622\n",
            "average loss in 13th itertaion 0.36935227587819097\n",
            "average loss in 14th itertaion 0.36083884194493293\n",
            "average loss in 15th itertaion 0.3325559955835342\n",
            "average loss in 16th itertaion 0.34596978401144346\n",
            "average loss in 17th itertaion 0.3218801117440065\n",
            "average loss in 18th itertaion 0.30648920113841693\n",
            "average loss in 19th itertaion 0.3039855390290419\n",
            "average loss in 20th itertaion 0.2882517418762048\n",
            "average loss in 21th itertaion 0.29939605832099914\n",
            "average loss in 22th itertaion 0.2750202135245005\n",
            "average loss in 23th itertaion 0.2649327968557676\n",
            "average loss in 24th itertaion 0.26234787337481974\n",
            "average loss in 25th itertaion 0.2752055888126294\n",
            "average loss in 26th itertaion 0.2569278032394747\n",
            "average loss in 27th itertaion 0.2531587779521942\n",
            "average loss in 28th itertaion 0.24396533357600372\n",
            "average loss in 29th itertaion 0.24430767017106214\n",
            "average loss in 30th itertaion 0.21841624386608602\n",
            "average loss in 31th itertaion 0.22299458255370458\n",
            "average loss in 32th itertaion 0.21597579980889955\n",
            "average loss in 33th itertaion 0.2025722675397992\n",
            "average loss in 34th itertaion 0.21019181462625663\n",
            "average loss in 35th itertaion 0.2440882566322883\n",
            "average loss in 36th itertaion 0.1953598121802012\n",
            "average loss in 37th itertaion 0.1924464847271641\n",
            "average loss in 38th itertaion 0.1886104441434145\n",
            "average loss in 39th itertaion 0.1757309282074372\n",
            "average loss in 40th itertaion 0.17001701399683952\n",
            "average loss in 41th itertaion 0.17608424598972003\n",
            "average loss in 42th itertaion 0.18007189922034741\n",
            "average loss in 43th itertaion 0.2079059993599852\n",
            "average loss in 44th itertaion 0.1649423214048147\n",
            "average loss in 45th itertaion 0.15555466171974938\n",
            "average loss in 46th itertaion 0.16084493239720662\n",
            "average loss in 47th itertaion 0.1473375367373228\n",
            "average loss in 48th itertaion 0.1595073953270912\n",
            "average loss in 49th itertaion 0.1539379112670819\n",
            "average loss in 50th itertaion 0.16339916452765466\n",
            "average loss in 51th itertaion 0.1466234783641994\n",
            "average loss in 52th itertaion 0.1333720139041543\n",
            "average loss in 53th itertaion 0.13679194708665213\n",
            "average loss in 54th itertaion 0.1338177041398982\n",
            "average loss in 55th itertaion 0.12711528805394967\n",
            "average loss in 56th itertaion 0.12089569710505506\n",
            "average loss in 57th itertaion 0.11733076460038622\n",
            "average loss in 58th itertaion 0.17281200688953202\n",
            "average loss in 59th itertaion 0.12755743897209565\n",
            "average loss in 60th itertaion 0.1648237465011577\n",
            "average loss in 61th itertaion 0.12443245368699232\n",
            "average loss in 62th itertaion 0.1385729535110295\n",
            "average loss in 63th itertaion 0.11535802462138235\n",
            "average loss in 64th itertaion 0.1169436817911143\n",
            "average loss in 65th itertaion 0.09759213294251821\n",
            "average loss in 66th itertaion 0.10302882746172448\n",
            "average loss in 67th itertaion 0.10088529228232801\n",
            "average loss in 68th itertaion 0.1415322090126574\n",
            "average loss in 69th itertaion 0.11395743433386088\n",
            "average loss in 70th itertaion 0.16929101331469915\n",
            "average loss in 71th itertaion 0.12612507841860254\n",
            "average loss in 72th itertaion 0.1010322708170861\n",
            "average loss in 73th itertaion 0.11146051611751318\n",
            "average loss in 74th itertaion 0.07431879673153162\n",
            "average loss in 75th itertaion 0.11188301070282856\n",
            "average loss in 76th itertaion 0.07662612153993299\n",
            "average loss in 77th itertaion 0.09684589724987745\n",
            "average loss in 78th itertaion 0.07731229026801884\n",
            "average loss in 79th itertaion 0.09199290820242216\n",
            "average loss in 80th itertaion 0.0858255428665628\n",
            "average loss in 81th itertaion 0.11312493266693006\n",
            "average loss in 82th itertaion 0.24504297000356018\n",
            "average loss in 83th itertaion 0.1067496057972312\n",
            "average loss in 84th itertaion 0.10401395708943406\n",
            "average loss in 85th itertaion 0.09871333867001036\n",
            "average loss in 86th itertaion 0.09593952404335142\n",
            "average loss in 87th itertaion 0.07020744893699885\n",
            "average loss in 88th itertaion 0.09061456228606403\n",
            "average loss in 89th itertaion 0.06610490336703757\n",
            "average loss in 90th itertaion 0.07905533956751848\n",
            "average loss in 91th itertaion 0.055263926212210206\n",
            "average loss in 92th itertaion 0.0650967749223734\n",
            "average loss in 93th itertaion 0.20918545852880924\n",
            "average loss in 94th itertaion 0.10046805360975365\n",
            "average loss in 95th itertaion 0.11238125338219106\n",
            "average loss in 96th itertaion 0.11516625330472986\n",
            "average loss in 97th itertaion 0.06652124514182409\n",
            "average loss in 98th itertaion 0.08868939878574263\n",
            "average loss in 99th itertaion 0.05890750114961217\n",
            "average loss in 100th itertaion 0.07436622166618084\n",
            "average loss in 101th itertaion 0.04238813489753132\n",
            "average loss in 102th itertaion 0.0455941936323264\n",
            "average loss in 103th itertaion 0.05856575151129315\n",
            "average loss in 104th itertaion 0.054428883186968355\n",
            "average loss in 105th itertaion 0.06435198367068855\n",
            "average loss in 106th itertaion 0.06393179623332496\n",
            "average loss in 107th itertaion 0.13607416076663262\n",
            "average loss in 108th itertaion 0.06072039394173771\n",
            "average loss in 109th itertaion 0.05023240494153773\n",
            "average loss in 110th itertaion 0.03687191274676782\n",
            "average loss in 111th itertaion 0.11319079203220705\n",
            "average loss in 112th itertaion 0.04810312130178014\n",
            "average loss in 113th itertaion 0.07213408063476284\n",
            "average loss in 114th itertaion 0.03306078211132747\n",
            "average loss in 115th itertaion 0.06399622108593273\n",
            "average loss in 116th itertaion 0.04413333261773611\n",
            "average loss in 117th itertaion 0.032884882397484036\n",
            "average loss in 118th itertaion 0.04993426454331105\n",
            "average loss in 119th itertaion 0.058240388423825305\n",
            "average loss in 120th itertaion 0.03487516786321066\n",
            "average loss in 121th itertaion 0.07359750633283207\n",
            "average loss in 122th itertaion 0.02142635724429662\n",
            "average loss in 123th itertaion 0.04013485377499213\n",
            "average loss in 124th itertaion 0.04108620342100039\n",
            "average loss in 125th itertaion 0.08104954748880118\n",
            "average loss in 126th itertaion 0.0530788323841989\n",
            "average loss in 127th itertaion 0.018432843075327887\n",
            "average loss in 128th itertaion 0.05259474996322145\n",
            "average loss in 129th itertaion 0.07253619642617802\n",
            "average loss in 130th itertaion 0.07615555279422552\n",
            "average loss in 131th itertaion 0.028370928771037144\n",
            "average loss in 132th itertaion 0.02549650270084385\n",
            "average loss in 133th itertaion 0.015104344117959651\n",
            "average loss in 134th itertaion 0.03231970219213205\n",
            "average loss in 135th itertaion 0.022581600775786987\n",
            "average loss in 136th itertaion 0.010940684427429612\n",
            "average loss in 137th itertaion 0.069297480750926\n",
            "average loss in 138th itertaion 0.023498011629950875\n",
            "average loss in 139th itertaion 0.016322271832323168\n",
            "average loss in 140th itertaion 0.013482995426941974\n",
            "average loss in 141th itertaion 0.007564130830578506\n",
            "average loss in 142th itertaion 0.038181731002308275\n",
            "average loss in 143th itertaion 0.14123954094170282\n",
            "average loss in 144th itertaion 0.028436834197491406\n",
            "average loss in 145th itertaion 0.04981558143588093\n",
            "average loss in 146th itertaion 0.10257901261638229\n",
            "average loss in 147th itertaion 0.0670839845823745\n",
            "average loss in 148th itertaion 0.04001947918906808\n",
            "average loss in 149th itertaion 0.01631770098232664\n",
            "average loss in 150th itertaion 0.01088369738640419\n",
            "average loss in 151th itertaion 0.006023957102588611\n",
            "average loss in 152th itertaion 0.008309339245703692\n",
            "average loss in 153th itertaion 0.0059647764679781785\n",
            "average loss in 154th itertaion 0.005289847684422663\n",
            "average loss in 155th itertaion 0.00721722401305063\n",
            "average loss in 156th itertaion 0.40902085501205876\n",
            "average loss in 157th itertaion 0.11342481658173104\n",
            "average loss in 158th itertaion 0.07385015964197615\n",
            "average loss in 159th itertaion 0.07591489393884937\n",
            "average loss in 160th itertaion 0.046147452824128174\n",
            "average loss in 161th itertaion 0.0706876176300769\n",
            "average loss in 162th itertaion 0.03462974222920214\n",
            "average loss in 163th itertaion 0.03651604580731752\n",
            "average loss in 164th itertaion 0.06102306107291952\n",
            "average loss in 165th itertaion 0.013358824564881312\n",
            "average loss in 166th itertaion 0.023357445723959244\n",
            "average loss in 167th itertaion 0.12224372755425672\n",
            "average loss in 168th itertaion 0.09054133124261474\n",
            "average loss in 169th itertaion 0.03368722002371214\n",
            "average loss in 170th itertaion 0.023962691124761477\n",
            "average loss in 171th itertaion 0.014883328391006216\n",
            "average loss in 172th itertaion 0.06623209937941282\n",
            "average loss in 173th itertaion 0.02493863731661501\n",
            "average loss in 174th itertaion 0.025245159281766974\n",
            "average loss in 175th itertaion 0.019708817380014808\n",
            "average loss in 176th itertaion 0.0076110402195869635\n",
            "average loss in 177th itertaion 0.008924110465304693\n",
            "average loss in 178th itertaion 0.00485798160196282\n",
            "average loss in 179th itertaion 0.0030800453747603265\n",
            "average loss in 180th itertaion 0.002755577768718164\n",
            "average loss in 181th itertaion 0.001982379197240031\n",
            "average loss in 182th itertaion 0.0019921522282917675\n",
            "average loss in 183th itertaion 0.0016909875870139027\n",
            "average loss in 184th itertaion 0.06512517210959534\n",
            "average loss in 185th itertaion 0.08190759513527154\n",
            "average loss in 186th itertaion 0.009165241720620543\n",
            "average loss in 187th itertaion 0.004318158626750422\n",
            "average loss in 188th itertaion 0.003057385001629882\n",
            "average loss in 189th itertaion 0.0036129779911910492\n",
            "average loss in 190th itertaion 0.001914346789465829\n",
            "average loss in 191th itertaion 0.001688749319849497\n",
            "average loss in 192th itertaion 0.0014628321014849158\n",
            "average loss in 193th itertaion 0.001360492780271064\n",
            "average loss in 194th itertaion 0.0012984105813666246\n",
            "average loss in 195th itertaion 0.0012373853176056097\n",
            "average loss in 196th itertaion 0.0011175000471121165\n",
            "average loss in 197th itertaion 0.0010603447298854008\n",
            "average loss in 198th itertaion 0.0010314599974662996\n",
            "average loss in 199th itertaion 0.0009542669338406995\n",
            "average loss in 200th itertaion 0.000924617193377344\n",
            "average loss in 201th itertaion 0.0008855387285196533\n",
            "average loss in 202th itertaion 0.0008708204545109766\n",
            "average loss in 203th itertaion 0.0008540541084948927\n",
            "average loss in 204th itertaion 0.000841301360099654\n",
            "average loss in 205th itertaion 0.0008221681798265006\n",
            "average loss in 206th itertaion 0.0008017947330154129\n",
            "average loss in 207th itertaion 0.0007765816088552432\n",
            "average loss in 208th itertaion 0.0007625309977932678\n",
            "average loss in 209th itertaion 0.0007470781560793209\n",
            "average loss in 210th itertaion 0.0007294487915593587\n",
            "average loss in 211th itertaion 0.0007340369909555496\n",
            "average loss in 212th itertaion 0.0007238161154721942\n",
            "average loss in 213th itertaion 0.0007141020160149007\n",
            "average loss in 214th itertaion 0.0007044501230120659\n",
            "average loss in 215th itertaion 0.0006910292470274726\n",
            "average loss in 216th itertaion 0.0006931028740170102\n",
            "average loss in 217th itertaion 0.000676028936674508\n",
            "average loss in 218th itertaion 0.0006788049926399253\n",
            "average loss in 219th itertaion 0.0006644383560342248\n",
            "average loss in 220th itertaion 0.0006653981851801897\n",
            "average loss in 221th itertaion 0.0006656747992383317\n",
            "average loss in 222th itertaion 0.0006579667903133668\n",
            "average loss in 223th itertaion 0.0006585280831253234\n",
            "average loss in 224th itertaion 0.000655548381691915\n",
            "average loss in 225th itertaion 0.000637264925026102\n",
            "average loss in 226th itertaion 0.0006427112627595004\n",
            "average loss in 227th itertaion 0.0006418548462049027\n",
            "average loss in 228th itertaion 0.0006420293145735438\n",
            "average loss in 229th itertaion 0.0006364947345112645\n",
            "average loss in 230th itertaion 0.0006372164529724008\n",
            "average loss in 231th itertaion 0.0006381997277882571\n",
            "average loss in 232th itertaion 0.0006272879866689133\n",
            "average loss in 233th itertaion 0.000632301015793928\n",
            "average loss in 234th itertaion 0.0006297765827912371\n",
            "average loss in 235th itertaion 0.0006325635943115534\n",
            "average loss in 236th itertaion 0.0006371758667713342\n",
            "average loss in 237th itertaion 0.0006252479743852746\n",
            "average loss in 238th itertaion 0.0006294093659622983\n",
            "average loss in 239th itertaion 0.0006244687258489042\n",
            "average loss in 240th itertaion 0.0006272048815784122\n",
            "average loss in 241th itertaion 0.0006314877161639743\n",
            "average loss in 242th itertaion 0.0006276738599990494\n",
            "average loss in 243th itertaion 0.0006205573061743053\n",
            "average loss in 244th itertaion 0.000623126505476345\n",
            "average loss in 245th itertaion 0.0006303889735621245\n",
            "average loss in 246th itertaion 0.0006269625089892846\n",
            "average loss in 247th itertaion 0.0006282399771104489\n",
            "average loss in 248th itertaion 0.0006213212252623634\n",
            "average loss in 249th itertaion 0.0006290055575179091\n",
            "average loss in 250th itertaion 0.0006289045308464362\n",
            "average loss in 251th itertaion 0.0006251520652828427\n",
            "average loss in 252th itertaion 0.00063137360921246\n",
            "average loss in 253th itertaion 0.0006320400957095748\n",
            "average loss in 254th itertaion 0.0006332548973053538\n",
            "average loss in 255th itertaion 0.0006264045821444597\n",
            "average loss in 256th itertaion 0.000632671266575926\n",
            "average loss in 257th itertaion 0.0006261280941301569\n",
            "average loss in 258th itertaion 0.0006371424896982111\n",
            "average loss in 259th itertaion 0.0006313123467649954\n",
            "average loss in 260th itertaion 0.0006320946948835626\n",
            "average loss in 261th itertaion 0.0006380259880582647\n",
            "average loss in 262th itertaion 0.0006394783428549999\n",
            "average loss in 263th itertaion 0.000637626219104277\n",
            "average loss in 264th itertaion 0.0006430595745526565\n",
            "average loss in 265th itertaion 0.0006432316826976603\n",
            "average loss in 266th itertaion 0.0006404001585663839\n",
            "average loss in 267th itertaion 0.0006519352784744115\n",
            "average loss in 268th itertaion 0.0006460771213460248\n",
            "average loss in 269th itertaion 0.0006469068387135242\n",
            "average loss in 270th itertaion 0.0006497105611197185\n",
            "average loss in 271th itertaion 0.0006509927505006393\n",
            "average loss in 272th itertaion 0.0006487060152479292\n",
            "average loss in 273th itertaion 0.0006520556409668643\n",
            "average loss in 274th itertaion 0.0006511754256886585\n",
            "average loss in 275th itertaion 0.0006541305307958586\n",
            "average loss in 276th itertaion 0.0006509752326625555\n",
            "average loss in 277th itertaion 0.0006604496222765495\n",
            "average loss in 278th itertaion 0.0006581898421427468\n",
            "average loss in 279th itertaion 0.0006545367449871264\n",
            "average loss in 280th itertaion 0.0006631330383970635\n",
            "average loss in 281th itertaion 0.0006599154937430285\n",
            "average loss in 282th itertaion 0.0006633297572261654\n",
            "average loss in 283th itertaion 0.0006663302920545296\n",
            "average loss in 284th itertaion 0.0006644374430470634\n",
            "average loss in 285th itertaion 0.0006693082323666506\n",
            "average loss in 286th itertaion 0.0006694664939035041\n",
            "average loss in 287th itertaion 0.0006708713527283787\n",
            "average loss in 288th itertaion 0.0006776911038711357\n",
            "average loss in 289th itertaion 0.0006780534079492402\n",
            "average loss in 290th itertaion 0.0006727640652873863\n",
            "average loss in 291th itertaion 0.0006774964112749634\n",
            "average loss in 292th itertaion 0.0006802512072742199\n",
            "average loss in 293th itertaion 0.0006863300816136568\n",
            "average loss in 294th itertaion 0.0006839187997684348\n",
            "average loss in 295th itertaion 0.0006852226703873991\n",
            "average loss in 296th itertaion 0.0006852244294229118\n",
            "average loss in 297th itertaion 0.0006859035382027893\n",
            "average loss in 298th itertaion 0.0006816763376021603\n",
            "average loss in 299th itertaion 0.0006858227660995908\n"
          ]
        }
      ],
      "source": [
        "for i in range(300):\n",
        "  total_loss = 0\n",
        "  for batch,batch_label in train_load:\n",
        "    out = Fn(batch)\n",
        "\n",
        "    loss = loss_func(out,batch_label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f'average loss in {i}th itertaion {total_loss/len(train_load)}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-dldu03I8xm",
        "outputId": "84e4d60a-dc2b-4c49-a7c7-c767b489cf11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NetsMan(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Fn.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0nTi9x3JAcn"
      },
      "outputs": [],
      "source": [
        "total = 0\n",
        "corr =0\n",
        "with torch.no_grad():\n",
        "  for batch,labels in test_load:\n",
        "    out = Fn(batch)\n",
        "    _,pred = torch.max(out,1)\n",
        "    total += labels.shape[0]\n",
        "    corr = corr + (labels == pred).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FhsJFP7J_Py",
        "outputId": "504037d0-9ab4-4418-f863-6843c975b107"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8433333333333334"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSP5gEixoZDG",
        "outputId": "e3d5a52e-b8b5-4daa-f17d-4180bc7aae8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhtMHaK7ohDh"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCQ06eq_pMMM"
      },
      "outputs": [],
      "source": [
        "X = d.drop(columns='label').to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNdFQCcwpgBg"
      },
      "outputs": [],
      "source": [
        "y = d['label'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-HXVTlTpie6"
      },
      "outputs": [],
      "source": [
        "X = X/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFaHX6kPpkyl"
      },
      "outputs": [],
      "source": [
        "Xn,yn = torch.tensor(X,dtype=torch.float),torch.tensor(y,dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXjoq_kIpsc9"
      },
      "outputs": [],
      "source": [
        "X_train,X_test = Xn[:8000],Xn[8000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjG5ORwvpyOu"
      },
      "outputs": [],
      "source": [
        "Y_train,Y_test = yn[:8000],yn[8000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-8syNEcp2Ai"
      },
      "outputs": [],
      "source": [
        "train_dataset = Customdata(X_train,Y_train)\n",
        "test_dataset = Customdata(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URVUTVCfqM2X"
      },
      "outputs": [],
      "source": [
        "train_load = DataLoader(train_dataset,batch_size=100,shuffle=True,pin_memory=True)\n",
        "test_load = DataLoader(test_dataset,batch_size=100,shuffle=False,pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtbxxL1yqc7d"
      },
      "outputs": [],
      "source": [
        "epoch = 100\n",
        "Lr  = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBlFv2ay4Q3k",
        "outputId": "0f7c120e-0c38-42d4-ad9b-d13b90a196bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W8cAHlWqi5x"
      },
      "outputs": [],
      "source": [
        "mynet = NetsMan(X.shape[1],10,3,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prbh8j9aqtIl"
      },
      "outputs": [],
      "source": [
        "mynet = mynet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIMYXzPosJm6"
      },
      "outputs": [],
      "source": [
        "loss2 = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfyRThu4sMVp"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.SGD(mynet.parameters(),lr=Lr,weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEL8xWk4q3iA",
        "outputId": "56fb0da7-e638-4fb0-92be-efecff46be11",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average loss in 0th itertaion 2.2877397179603576\n",
            "average loss in 1th itertaion 1.8484997525811195\n",
            "average loss in 2th itertaion 1.185305979847908\n",
            "average loss in 3th itertaion 0.9965927422046661\n",
            "average loss in 4th itertaion 0.7967727772891522\n",
            "average loss in 5th itertaion 0.7403516434133053\n",
            "average loss in 6th itertaion 0.6902879312634468\n",
            "average loss in 7th itertaion 0.638441252335906\n",
            "average loss in 8th itertaion 0.6075480442494154\n",
            "average loss in 9th itertaion 0.5787532094866037\n",
            "average loss in 10th itertaion 0.5526738073676825\n",
            "average loss in 11th itertaion 0.5816424958407879\n",
            "average loss in 12th itertaion 0.5276512887328864\n",
            "average loss in 13th itertaion 0.5090714015066624\n",
            "average loss in 14th itertaion 0.4969249252229929\n",
            "average loss in 15th itertaion 0.48126371912658217\n",
            "average loss in 16th itertaion 0.5207609064877033\n",
            "average loss in 17th itertaion 0.46517053097486494\n",
            "average loss in 18th itertaion 0.4588720466941595\n",
            "average loss in 19th itertaion 0.4392743639647961\n",
            "average loss in 20th itertaion 0.43108646012842655\n",
            "average loss in 21th itertaion 0.4157851096242666\n",
            "average loss in 22th itertaion 0.4024010971188545\n",
            "average loss in 23th itertaion 0.4097776310518384\n",
            "average loss in 24th itertaion 0.38341045323759315\n",
            "average loss in 25th itertaion 0.38763608802109956\n",
            "average loss in 26th itertaion 0.37576171178370715\n",
            "average loss in 27th itertaion 0.3609232293441892\n",
            "average loss in 28th itertaion 0.36531588044017554\n",
            "average loss in 29th itertaion 0.35481252521276474\n",
            "average loss in 30th itertaion 0.34909982345998286\n",
            "average loss in 31th itertaion 0.3448309464380145\n",
            "average loss in 32th itertaion 0.3295552344992757\n",
            "average loss in 33th itertaion 0.3317382957786322\n",
            "average loss in 34th itertaion 0.3279950933530927\n",
            "average loss in 35th itertaion 0.3110559232532978\n",
            "average loss in 36th itertaion 0.3164818573743105\n",
            "average loss in 37th itertaion 0.31275013983249667\n",
            "average loss in 38th itertaion 0.30470112767070534\n",
            "average loss in 39th itertaion 0.29314371924847366\n",
            "average loss in 40th itertaion 0.3004672430455685\n",
            "average loss in 41th itertaion 0.2997888669371605\n",
            "average loss in 42th itertaion 0.2792403597384691\n",
            "average loss in 43th itertaion 0.27570046093314887\n",
            "average loss in 44th itertaion 0.2890600996091962\n",
            "average loss in 45th itertaion 0.2650354621000588\n",
            "average loss in 46th itertaion 0.3024880362674594\n",
            "average loss in 47th itertaion 0.26335601732134817\n",
            "average loss in 48th itertaion 0.2631888693198562\n",
            "average loss in 49th itertaion 0.2597992504015565\n",
            "average loss in 50th itertaion 0.25397626915946603\n",
            "average loss in 51th itertaion 0.2527998462319374\n",
            "average loss in 52th itertaion 0.23745542000979186\n",
            "average loss in 53th itertaion 0.24974636267870665\n",
            "average loss in 54th itertaion 0.2402806212194264\n",
            "average loss in 55th itertaion 0.25674923695623875\n",
            "average loss in 56th itertaion 0.22569666625931858\n",
            "average loss in 57th itertaion 0.23085468830540776\n",
            "average loss in 58th itertaion 0.2136609550565481\n",
            "average loss in 59th itertaion 0.2299333555623889\n",
            "average loss in 60th itertaion 0.21782060908153653\n",
            "average loss in 61th itertaion 0.22531990874558688\n",
            "average loss in 62th itertaion 0.20484181633219123\n",
            "average loss in 63th itertaion 0.23482585595920683\n",
            "average loss in 64th itertaion 0.669299041107297\n",
            "average loss in 65th itertaion 0.2919080024585128\n",
            "average loss in 66th itertaion 0.26750469002872707\n",
            "average loss in 67th itertaion 0.3469006668776274\n",
            "average loss in 68th itertaion 0.23767836205661297\n",
            "average loss in 69th itertaion 0.25526624349877236\n",
            "average loss in 70th itertaion 0.2236229505389929\n",
            "average loss in 71th itertaion 0.23940924145281314\n",
            "average loss in 72th itertaion 0.21938429148867727\n",
            "average loss in 73th itertaion 0.20322859147563577\n",
            "average loss in 74th itertaion 0.20164170572534204\n",
            "average loss in 75th itertaion 0.20634695729240776\n",
            "average loss in 76th itertaion 0.20593269830569624\n",
            "average loss in 77th itertaion 0.18957534227520229\n",
            "average loss in 78th itertaion 0.19083313103765248\n",
            "average loss in 79th itertaion 0.20541716488078238\n",
            "average loss in 80th itertaion 0.17327463114634156\n",
            "average loss in 81th itertaion 0.1710615518502891\n",
            "average loss in 82th itertaion 0.31197475204244257\n",
            "average loss in 83th itertaion 0.19311486091464758\n",
            "average loss in 84th itertaion 0.1765206392854452\n",
            "average loss in 85th itertaion 0.17577783055603505\n",
            "average loss in 86th itertaion 0.20029687182977796\n",
            "average loss in 87th itertaion 0.16067921286448836\n",
            "average loss in 88th itertaion 0.16810538875870407\n",
            "average loss in 89th itertaion 0.16594039956107737\n",
            "average loss in 90th itertaion 0.16068590292707086\n",
            "average loss in 91th itertaion 0.1571917853318155\n",
            "average loss in 92th itertaion 0.14241606863215567\n",
            "average loss in 93th itertaion 0.16172056859359146\n",
            "average loss in 94th itertaion 0.16878865603357554\n",
            "average loss in 95th itertaion 0.14183095623739064\n",
            "average loss in 96th itertaion 0.1625637356657535\n",
            "average loss in 97th itertaion 0.17565371566452087\n",
            "average loss in 98th itertaion 0.14571692510508\n",
            "average loss in 99th itertaion 0.16225311299785972\n"
          ]
        }
      ],
      "source": [
        "for i in range(epoch):\n",
        "  total_loss = 0\n",
        "  for batch,batch_label in train_load:\n",
        "    batch,batch_label = batch.to(device), batch_label.to(device)\n",
        "    out = mynet(batch)\n",
        "\n",
        "    loss = loss2(out,batch_label)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f'average loss in {i}th itertaion {total_loss/len(train_load)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txZd80Les09D",
        "outputId": "077f9257-b35f-4fdf-b113-116416ff4386"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NetsMan(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mynet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXkGmpiCs2YI",
        "outputId": "8e74e9ac-6813-44b8-d38d-6bee52bb11d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.852\n"
          ]
        }
      ],
      "source": [
        "total=0\n",
        "corr = 0\n",
        "with torch.no_grad():\n",
        "  for batch,batch_label in test_load:\n",
        "    batch,batch_label = batch.to(device),batch_label.to(device)\n",
        "    out = mynet(batch)\n",
        "    _,pred = torch.max(out,1)\n",
        "    total += batch.shape[0]\n",
        "    corr = corr + (pred == batch_label).sum().item()\n",
        "print(corr/total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgcnJper4zZF"
      },
      "source": [
        "Optimizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7xnHvo140tT"
      },
      "outputs": [],
      "source": [
        "class NetsMan2(nn.Module):\n",
        "  def __init__(self,input_s,output_s,hidden_layers,num_neurons):\n",
        "    super().__init__()\n",
        "    layers = [ nn.Linear(in_features=input_s,out_features=num_neurons),\n",
        "              nn.BatchNorm1d(num_neurons),\n",
        "              nn.ReLU(),\n",
        "               nn.Dropout(p=0.3)]\n",
        "    for i in range(hidden_layers):\n",
        "      layers.append(\n",
        "          nn.Linear(in_features=num_neurons,out_features=num_neurons)\n",
        "      )\n",
        "      layers.append(nn.BatchNorm1d(num_neurons))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(p=0.3))\n",
        "    layers.append(\n",
        "        nn.Linear(in_features=num_neurons,out_features=output_s)\n",
        "    )\n",
        "\n",
        "\n",
        "    self.network = nn.Sequential(*layers)\n",
        "  def forward(self,x):\n",
        "    return self.network(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_Vaydp15TeC"
      },
      "outputs": [],
      "source": [
        "model = NetsMan2(X.shape[1],10,3,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVcX0hsQ5aj3"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb2Foth85cLX"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvknyJ725gRR"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.SGD(model.parameters(),lr=0.1,weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQIdowCa5qco",
        "outputId": "a03980d8-df77-4187-c008-3472923d9762",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "average batch error in 0th iter is 1.4467497490346433\n",
            "average batch error in 1th iter is 0.8958900436758995\n",
            "average batch error in 2th iter is 0.7736209318041801\n",
            "average batch error in 3th iter is 0.7063088018447161\n",
            "average batch error in 4th iter is 0.6688782814890146\n",
            "average batch error in 5th iter is 0.6284949939697981\n",
            "average batch error in 6th iter is 0.6042103879153728\n",
            "average batch error in 7th iter is 0.59190215729177\n",
            "average batch error in 8th iter is 0.5691602490842342\n",
            "average batch error in 9th iter is 0.5652155160903931\n",
            "average batch error in 10th iter is 0.5434278581291437\n",
            "average batch error in 11th iter is 0.5321978472173214\n",
            "average batch error in 12th iter is 0.5231235776096582\n",
            "average batch error in 13th iter is 0.5159492712467909\n",
            "average batch error in 14th iter is 0.5071132991462945\n",
            "average batch error in 15th iter is 0.4864389464259148\n",
            "average batch error in 16th iter is 0.47680201977491377\n",
            "average batch error in 17th iter is 0.4773361194878817\n",
            "average batch error in 18th iter is 0.4664105521515012\n",
            "average batch error in 19th iter is 0.461889885365963\n",
            "average batch error in 20th iter is 0.4442814437672496\n",
            "average batch error in 21th iter is 0.44282429330050943\n",
            "average batch error in 22th iter is 0.44941298812627795\n",
            "average batch error in 23th iter is 0.4281729459762573\n",
            "average batch error in 24th iter is 0.42755945958197117\n",
            "average batch error in 25th iter is 0.42547506764531134\n",
            "average batch error in 26th iter is 0.42252264842391013\n",
            "average batch error in 27th iter is 0.4098153062164783\n",
            "average batch error in 28th iter is 0.41790729742497207\n",
            "average batch error in 29th iter is 0.39792358987033366\n",
            "average batch error in 30th iter is 0.40539989471435545\n",
            "average batch error in 31th iter is 0.4014344088733196\n",
            "average batch error in 32th iter is 0.39297112058848144\n",
            "average batch error in 33th iter is 0.37914223615080117\n",
            "average batch error in 34th iter is 0.36899236161261795\n",
            "average batch error in 35th iter is 0.3706625312566757\n",
            "average batch error in 36th iter is 0.377985399030149\n",
            "average batch error in 37th iter is 0.380982893332839\n",
            "average batch error in 38th iter is 0.37421422079205513\n",
            "average batch error in 39th iter is 0.369114506803453\n",
            "average batch error in 40th iter is 0.3600644938647747\n",
            "average batch error in 41th iter is 0.3538562338799238\n",
            "average batch error in 42th iter is 0.3520599344745278\n",
            "average batch error in 43th iter is 0.340994774363935\n",
            "average batch error in 44th iter is 0.3496362179517746\n",
            "average batch error in 45th iter is 0.3423115389421582\n",
            "average batch error in 46th iter is 0.33431493062525985\n",
            "average batch error in 47th iter is 0.33829816840589044\n",
            "average batch error in 48th iter is 0.3389747854322195\n",
            "average batch error in 49th iter is 0.33102961238473655\n",
            "average batch error in 50th iter is 0.32332812529057264\n",
            "average batch error in 51th iter is 0.33240625374019145\n",
            "average batch error in 52th iter is 0.31528808884322646\n",
            "average batch error in 53th iter is 0.3282555639743805\n",
            "average batch error in 54th iter is 0.3160022312775254\n",
            "average batch error in 55th iter is 0.3213598486036062\n",
            "average batch error in 56th iter is 0.31259518265724184\n",
            "average batch error in 57th iter is 0.29742040373384954\n",
            "average batch error in 58th iter is 0.3131907359696925\n",
            "average batch error in 59th iter is 0.31095533538609743\n",
            "average batch error in 60th iter is 0.30824132934212684\n",
            "average batch error in 61th iter is 0.308821289613843\n",
            "average batch error in 62th iter is 0.2967848315834999\n",
            "average batch error in 63th iter is 0.2925111768767238\n",
            "average batch error in 64th iter is 0.2906224686652422\n",
            "average batch error in 65th iter is 0.303441188018769\n",
            "average batch error in 66th iter is 0.307085738517344\n",
            "average batch error in 67th iter is 0.2917644402012229\n",
            "average batch error in 68th iter is 0.29017517548054456\n",
            "average batch error in 69th iter is 0.2924248453229666\n",
            "average batch error in 70th iter is 0.2881341641768813\n",
            "average batch error in 71th iter is 0.2947829058393836\n",
            "average batch error in 72th iter is 0.2911109790205956\n",
            "average batch error in 73th iter is 0.28221632856875656\n",
            "average batch error in 74th iter is 0.2597474815323949\n",
            "average batch error in 75th iter is 0.2870748069137335\n",
            "average batch error in 76th iter is 0.262934104166925\n",
            "average batch error in 77th iter is 0.27141499510034917\n",
            "average batch error in 78th iter is 0.2770898761227727\n",
            "average batch error in 79th iter is 0.27765119429677726\n",
            "average batch error in 80th iter is 0.2697063684463501\n",
            "average batch error in 81th iter is 0.27652700785547496\n",
            "average batch error in 82th iter is 0.2578014561906457\n",
            "average batch error in 83th iter is 0.27565825134515765\n",
            "average batch error in 84th iter is 0.2577539451420307\n",
            "average batch error in 85th iter is 0.2616808387450874\n",
            "average batch error in 86th iter is 0.2687297949567437\n",
            "average batch error in 87th iter is 0.25939874798059465\n",
            "average batch error in 88th iter is 0.24499928057193757\n",
            "average batch error in 89th iter is 0.25880148969590666\n",
            "average batch error in 90th iter is 0.261355837713927\n",
            "average batch error in 91th iter is 0.25729816732928157\n",
            "average batch error in 92th iter is 0.24780985433608294\n",
            "average batch error in 93th iter is 0.24327113721519708\n",
            "average batch error in 94th iter is 0.26286208629608154\n",
            "average batch error in 95th iter is 0.24675072971731424\n",
            "average batch error in 96th iter is 0.24966870686039327\n",
            "average batch error in 97th iter is 0.24482681220397354\n",
            "average batch error in 98th iter is 0.24396848129108548\n",
            "average batch error in 99th iter is 0.24157787598669528\n"
          ]
        }
      ],
      "source": [
        "for i in range(epoch):\n",
        "  total =0\n",
        "  for batch,batch_label in train_load:\n",
        "    batch,batch_label = batch.to(device),batch_label.to(device)\n",
        "    out = model(batch)\n",
        "    loss = loss_function(out,batch_label)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    total += loss.item()\n",
        "  print(f'average batch error in {i}th iter is {total/len(train_load)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jvsB5R46U6X",
        "outputId": "2779f17f-f492-486d-8805-70f1de07b8e5",
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NetsMan2(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
              "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.3, inplace=False)\n",
              "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.3, inplace=False)\n",
              "    (12): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU()\n",
              "    (15): Dropout(p=0.3, inplace=False)\n",
              "    (16): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhvgpH4T6WeA",
        "outputId": "af6211f2-9747-42a2-d24e-92b296d00372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8665\n"
          ]
        }
      ],
      "source": [
        "total=0\n",
        "corr =0\n",
        "with torch.no_grad():\n",
        "  for batch,batch_label in test_load:\n",
        "    batch,batch_label = batch.to(device),batch_label.to(device)\n",
        "    out = model(batch)\n",
        "    _,preds = torch.max(out,1)\n",
        "    total += batch.shape[0]\n",
        "    corr += (preds == batch_label).sum().item()\n",
        "print(corr/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wMep9I-7SSg",
        "outputId": "fb9d4afe-da70-468e-ae9a-1ac49a13429c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.951625\n"
          ]
        }
      ],
      "source": [
        "total=0\n",
        "corr =0\n",
        "with torch.no_grad():\n",
        "  for batch,batch_label in train_load:\n",
        "    batch,batch_label = batch.to(device),batch_label.to(device)\n",
        "    out = model(batch)\n",
        "    _,preds = torch.max(out,1)\n",
        "    total += batch.shape[0]\n",
        "    corr += (preds == batch_label).sum().item()\n",
        "print(corr/total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWhuPEnrNkuz"
      },
      "source": [
        "HyperParameter Tunning with optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2NhraIfNoG6",
        "outputId": "07424551-6f00-4ff4-e0e6-e6e92f697ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/404.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FnyM24JPyJZ"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhFFGVMwNqKE"
      },
      "outputs": [],
      "source": [
        "def objective(trail):\n",
        "  hidd_layers = trail.suggest_int('number_hidden_layers',1,5)\n",
        "  n_neurons = trail.suggest_int('number_of_neurons',8,128,step=8)\n",
        "\n",
        "  model = NetsMan2(784,10,hidd_layers,n_neurons)\n",
        "  model = model.to(device)\n",
        "\n",
        "  epoch = 50\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  opt = torch.optim.SGD(model.parameters(),lr=0.1,weight_decay=1e-4)\n",
        "  for _ in range(epoch):\n",
        "    for batch,batch_label in train_load:\n",
        "      batch = batch.to(device)\n",
        "      batch_label = batch_label.to(device)\n",
        "      out = model(batch)\n",
        "      loss = loss_func(out,batch_label)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "  total= 0\n",
        "  corr =0\n",
        "  for batch,batch_label in test_load:\n",
        "    batch = batch.to(device)\n",
        "    batch_label = batch_label.to(device)\n",
        "    out = model(batch)\n",
        "    _,pred = torch.max(out,1)\n",
        "    total += batch.shape[0]\n",
        "    corr += (pred == batch_label).sum().item()\n",
        "\n",
        "  return corr/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8frJRfUQLOA",
        "outputId": "c96caeb4-54ca-460c-e135-22fef13ce172"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-25 04:49:51,874] A new study created in memory with name: no-name-0dfb5225-21ef-4b8f-b189-fce516039c12\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='maximize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIDuyhtPQfJb",
        "outputId": "663245e9-5be2-451f-cab5-bc678e59dd18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-25 04:50:11,321] Trial 0 finished with value: 0.7805 and parameters: {'number_hidden_layers': 3, 'number_of_neurons': 32}. Best is trial 0 with value: 0.7805.\n",
            "[I 2025-11-25 04:50:26,040] Trial 1 finished with value: 0.758 and parameters: {'number_hidden_layers': 2, 'number_of_neurons': 24}. Best is trial 0 with value: 0.7805.\n",
            "[I 2025-11-25 04:50:42,654] Trial 2 finished with value: 0.843 and parameters: {'number_hidden_layers': 3, 'number_of_neurons': 96}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:50:57,918] Trial 3 finished with value: 0.8185 and parameters: {'number_hidden_layers': 2, 'number_of_neurons': 48}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:51:14,326] Trial 4 finished with value: 0.837 and parameters: {'number_hidden_layers': 3, 'number_of_neurons': 96}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:51:29,228] Trial 5 finished with value: 0.8215 and parameters: {'number_hidden_layers': 2, 'number_of_neurons': 48}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:51:42,255] Trial 6 finished with value: 0.832 and parameters: {'number_hidden_layers': 1, 'number_of_neurons': 56}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:51:55,243] Trial 7 finished with value: 0.841 and parameters: {'number_hidden_layers': 1, 'number_of_neurons': 88}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:52:09,930] Trial 8 finished with value: 0.838 and parameters: {'number_hidden_layers': 2, 'number_of_neurons': 128}. Best is trial 2 with value: 0.843.\n",
            "[I 2025-11-25 04:52:26,316] Trial 9 finished with value: 0.841 and parameters: {'number_hidden_layers': 3, 'number_of_neurons': 128}. Best is trial 2 with value: 0.843.\n"
          ]
        }
      ],
      "source": [
        "study.optimize(objective,n_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BQdR7qCQmJN",
        "outputId": "e8bab762-d031-4b7c-e1ea-4d6934262203"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.843"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_trial.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_bMHyVzam3x",
        "outputId": "0b553413-9785-4b0a-a35e-8555973c2008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values([3, 96])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EgnkJ2eeap7x",
        "outputId": "fe27a724-6785-4176-b944-a81127b07bc5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "d"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c0b3aacc-29e7-4efe-b628-8dd7a0a00c9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>175</td>\n",
              "      <td>172</td>\n",
              "      <td>172</td>\n",
              "      <td>182</td>\n",
              "      <td>199</td>\n",
              "      <td>222</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>111</td>\n",
              "      <td>95</td>\n",
              "      <td>75</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0b3aacc-29e7-4efe-b628-8dd7a0a00c9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0b3aacc-29e7-4efe-b628-8dd7a0a00c9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0b3aacc-29e7-4efe-b628-8dd7a0a00c9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-64154bb3-f6da-48c4-bd04-79e7562c8222\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64154bb3-f6da-48c4-bd04-79e7562c8222')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-64154bb3-f6da-48c4-bd04-79e7562c8222 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a4f13ad7-4c73-4dde-afda-3c1cb0fe62a0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('d')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a4f13ad7-4c73-4dde-afda-3c1cb0fe62a0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('d');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0         0       0       0       0       0       0       0       0       9   \n",
              "1         1       0       0       0       0       0       0       0       0   \n",
              "2         2       0       0       0       0       0       0      14      53   \n",
              "3         2       0       0       0       0       0       0       0       0   \n",
              "4         3       0       0       0       0       0       0       0       0   \n",
              "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "9995      0       0       0       0       0       0       0       0       0   \n",
              "9996      6       0       0       0       0       0       0       0       0   \n",
              "9997      8       0       0       0       0       0       0       0       0   \n",
              "9998      8       0       1       3       0       0       0       0       0   \n",
              "9999      1       0       0       0       0       0       0       0     140   \n",
              "\n",
              "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0          8  ...       103        87        56         0         0         0   \n",
              "1          0  ...        34         0         0         0         0         0   \n",
              "2         99  ...         0         0         0         0        63        53   \n",
              "3          0  ...       137       126       140         0       133       224   \n",
              "4          0  ...         0         0         0         0         0         0   \n",
              "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
              "9995       0  ...        32        23        14        20         0         0   \n",
              "9996       0  ...         0         0         0         2        52        23   \n",
              "9997       0  ...       175       172       172       182       199       222   \n",
              "9998       0  ...         0         0         0         0         0         1   \n",
              "9999     119  ...       111        95        75        44         1         0   \n",
              "\n",
              "      pixel781  pixel782  pixel783  pixel784  \n",
              "0            0         0         0         0  \n",
              "1            0         0         0         0  \n",
              "2           31         0         0         0  \n",
              "3          222        56         0         0  \n",
              "4            0         0         0         0  \n",
              "...        ...       ...       ...       ...  \n",
              "9995         1         0         0         0  \n",
              "9996        28         0         0         0  \n",
              "9997        42         0         1         0  \n",
              "9998         0         0         0         0  \n",
              "9999         0         0         0         0  \n",
              "\n",
              "[10000 rows x 785 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmGakRNMXxGk",
        "outputId": "73056b42-20d1-457a-a6f0-032cc1b3f145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TokWfe-HXJxj",
        "outputId": "fef63b45-84dd-42b8-88b9-2b382c6470da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "features = d.drop(columns='label')\n",
        "label = d['label']\n",
        "fig,axes = plt.subplots(2,5,figsize=(12,5))\n",
        "for i in range(10):\n",
        "  im = features.iloc[i].values.reshape(28,28)\n",
        "  ax = axes[i // 5, i% 5]\n",
        "  ax.imshow(im,cmap='grey')\n",
        "  ax.set_title(f\"Label: {label.iloc[i]}\")\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ3r6zMZZY3G"
      },
      "source": [
        "Lets build CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CinCVNDpcBGh"
      },
      "outputs": [],
      "source": [
        "class Customdata(Dataset):\n",
        "  def __init__(self,feature,target):\n",
        "    self.features = feature.reshape(-1,1,28,28)\n",
        "    self.target = target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "\n",
        "    return self.features[index] , self.target[index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW0L0epfdQ6H"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(d.drop(columns='label').to_numpy() , dtype=torch.float)\n",
        "y = torch.tensor(d['label'].to_numpy(),dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmkJR0nadXUx"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knsx8acse44e",
        "outputId": "09ef96d6-ddba-49f4-f248-e86f98002c12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
              "        ...,\n",
              "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
              "        [  0.,   0.,   0.,  ..., 115.,  35.,   0.],\n",
              "        [  0.,   0.,   0.,  ...,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrYjR0npdece"
      },
      "outputs": [],
      "source": [
        "train_data = Customdata(X_train,Y_train)\n",
        "test_data = Customdata(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeOlkUYbfCuo"
      },
      "outputs": [],
      "source": [
        "train = DataLoader(train_data,batch_size=32,shuffle=True,pin_memory=True)\n",
        "test = DataLoader(test_data,batch_size=32,shuffle=False,pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8mdZ1mhZYkm"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "class Mycnn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.filter = nn.Sequential(\n",
        "        nn.Conv2d(1,32,3,1,1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "        nn.Conv2d(32,64,3,1,1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(3136,1000,bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm1d(1000),\n",
        "        nn.Dropout(p=0.4),\n",
        "        nn.Linear(1000,10,bias=True),\n",
        "\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    f = self.filter(x)\n",
        "\n",
        "    y = self.layers(f)\n",
        "    return y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yihr3OP3h3kM"
      },
      "outputs": [],
      "source": [
        "cnn = Mycnn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE_fRSjUh_9U",
        "outputId": "65b5fa13-480b-4cf2-d43a-4106bfeeeebf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjFycYW_iN4B"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmPAjsfviQqb"
      },
      "outputs": [],
      "source": [
        "cnn = cnn.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mvxjc9CiS9d"
      },
      "outputs": [],
      "source": [
        "epoch = 100\n",
        "learning_rate = 3e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcsYXVm7iZCg"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMzRolr8idac"
      },
      "outputs": [],
      "source": [
        "optm = torch.optim.Adam(cnn.parameters(),lr=learning_rate,weight_decay=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_6XDFnbiqiq",
        "outputId": "c1470003-2c51-41ec-e1cb-0b6f85063ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss per batch in 0th epoch is 0.5179659872055054\n",
            "average loss per batch in 1th epoch is 0.31704594984650614\n",
            "average loss per batch in 2th epoch is 0.25174033361673354\n",
            "average loss per batch in 3th epoch is 0.1922003103941679\n",
            "average loss per batch in 4th epoch is 0.16060150791704655\n",
            "average loss per batch in 5th epoch is 0.12027767715603113\n",
            "average loss per batch in 6th epoch is 0.10146064815297723\n",
            "average loss per batch in 7th epoch is 0.0960576012544334\n",
            "average loss per batch in 8th epoch is 0.06739218041673303\n",
            "average loss per batch in 9th epoch is 0.05550392203405499\n",
            "average loss per batch in 10th epoch is 0.054107538320124146\n",
            "average loss per batch in 11th epoch is 0.056852779239416125\n",
            "average loss per batch in 12th epoch is 0.051130845434963705\n",
            "average loss per batch in 13th epoch is 0.038280436878092586\n",
            "average loss per batch in 14th epoch is 0.044110730197280644\n",
            "average loss per batch in 15th epoch is 0.03937023016996682\n",
            "average loss per batch in 16th epoch is 0.033373314484953884\n",
            "average loss per batch in 17th epoch is 0.04093332112021744\n",
            "average loss per batch in 18th epoch is 0.04021718372032047\n",
            "average loss per batch in 19th epoch is 0.037618914218619466\n",
            "average loss per batch in 20th epoch is 0.027983331153169276\n",
            "average loss per batch in 21th epoch is 0.030698617710731922\n",
            "average loss per batch in 22th epoch is 0.023777574193663897\n",
            "average loss per batch in 23th epoch is 0.022572198915295303\n",
            "average loss per batch in 24th epoch is 0.030324202469550074\n",
            "average loss per batch in 25th epoch is 0.056031383592635396\n",
            "average loss per batch in 26th epoch is 0.042708133310079575\n",
            "average loss per batch in 27th epoch is 0.023895946049131454\n",
            "average loss per batch in 28th epoch is 0.014237670968286693\n",
            "average loss per batch in 29th epoch is 0.012426466426812112\n",
            "average loss per batch in 30th epoch is 0.01675895151030272\n",
            "average loss per batch in 31th epoch is 0.03899214597977698\n",
            "average loss per batch in 32th epoch is 0.03981792936660349\n",
            "average loss per batch in 33th epoch is 0.026399924540892242\n",
            "average loss per batch in 34th epoch is 0.023508246958255766\n",
            "average loss per batch in 35th epoch is 0.018289658296853303\n",
            "average loss per batch in 36th epoch is 0.018847759920172392\n",
            "average loss per batch in 37th epoch is 0.015751826545223592\n",
            "average loss per batch in 38th epoch is 0.026498452636413275\n",
            "average loss per batch in 39th epoch is 0.028296082699671387\n",
            "average loss per batch in 40th epoch is 0.037996139072813094\n",
            "average loss per batch in 41th epoch is 0.03100969136413187\n",
            "average loss per batch in 42th epoch is 0.018789361014962196\n",
            "average loss per batch in 43th epoch is 0.022405359462834895\n",
            "average loss per batch in 44th epoch is 0.016441806389018893\n",
            "average loss per batch in 45th epoch is 0.010185018920339644\n",
            "average loss per batch in 46th epoch is 0.013136033546179532\n",
            "average loss per batch in 47th epoch is 0.02837091220356524\n",
            "average loss per batch in 48th epoch is 0.03719873596355319\n",
            "average loss per batch in 49th epoch is 0.06508652178943157\n",
            "average loss per batch in 50th epoch is 0.017212606062181293\n",
            "average loss per batch in 51th epoch is 0.00888277568295598\n",
            "average loss per batch in 52th epoch is 0.006829678618814796\n",
            "average loss per batch in 53th epoch is 0.004899183611385524\n",
            "average loss per batch in 54th epoch is 0.007781021977309137\n",
            "average loss per batch in 55th epoch is 0.025817110487259924\n",
            "average loss per batch in 56th epoch is 0.048608305115252735\n",
            "average loss per batch in 57th epoch is 0.029704812111333013\n",
            "average loss per batch in 58th epoch is 0.01570890446100384\n",
            "average loss per batch in 59th epoch is 0.008068563550710678\n",
            "average loss per batch in 60th epoch is 0.0060723338653333485\n",
            "average loss per batch in 61th epoch is 0.005917855975218117\n",
            "average loss per batch in 62th epoch is 0.005691536904778332\n",
            "average loss per batch in 63th epoch is 0.03825472788140178\n",
            "average loss per batch in 64th epoch is 0.06036068333685398\n",
            "average loss per batch in 65th epoch is 0.028239144997671245\n",
            "average loss per batch in 66th epoch is 0.01718520577158779\n",
            "average loss per batch in 67th epoch is 0.014159280085470528\n",
            "average loss per batch in 68th epoch is 0.008167075411882252\n",
            "average loss per batch in 69th epoch is 0.006271517153363675\n",
            "average loss per batch in 70th epoch is 0.005689463908784092\n",
            "average loss per batch in 71th epoch is 0.007315704861655831\n",
            "average loss per batch in 72th epoch is 0.01942140227649361\n",
            "average loss per batch in 73th epoch is 0.05568729429505766\n",
            "average loss per batch in 74th epoch is 0.03322089863009751\n",
            "average loss per batch in 75th epoch is 0.019221007293090224\n",
            "average loss per batch in 76th epoch is 0.010428130558226258\n",
            "average loss per batch in 77th epoch is 0.009080163959879428\n",
            "average loss per batch in 78th epoch is 0.006391994475387037\n",
            "average loss per batch in 79th epoch is 0.005348759811371565\n",
            "average loss per batch in 80th epoch is 0.008641329835169017\n",
            "average loss per batch in 81th epoch is 0.024661312125623225\n",
            "average loss per batch in 82th epoch is 0.03856278048455715\n",
            "average loss per batch in 83th epoch is 0.030682827232405542\n",
            "average loss per batch in 84th epoch is 0.0170051346430555\n",
            "average loss per batch in 85th epoch is 0.010552301588002593\n",
            "average loss per batch in 86th epoch is 0.008296633668243885\n",
            "average loss per batch in 87th epoch is 0.0055675280392169955\n",
            "average loss per batch in 88th epoch is 0.0047270281203091145\n",
            "average loss per batch in 89th epoch is 0.0060526364641264084\n",
            "average loss per batch in 90th epoch is 0.03980835407646373\n",
            "average loss per batch in 91th epoch is 0.047769491827115415\n",
            "average loss per batch in 92th epoch is 0.021754268635995687\n",
            "average loss per batch in 93th epoch is 0.01594963227212429\n",
            "average loss per batch in 94th epoch is 0.013947874138131738\n",
            "average loss per batch in 95th epoch is 0.007598459346685559\n",
            "average loss per batch in 96th epoch is 0.00536165885720402\n",
            "average loss per batch in 97th epoch is 0.005064586527179927\n",
            "average loss per batch in 98th epoch is 0.004608337420038879\n",
            "average loss per batch in 99th epoch is 0.004810335862915963\n"
          ]
        }
      ],
      "source": [
        "for i in range(epoch):\n",
        "  av_loss = 0\n",
        "  cnn.train()\n",
        "  for batch,batch_label  in train:\n",
        "    batch =batch.to(device)\n",
        "    batch_label = batch_label.to(device)\n",
        "\n",
        "    out = cnn(batch)\n",
        "    _,pred = torch.max(out,1)\n",
        "    loss = loss_func(out,batch_label)\n",
        "    optm.zero_grad()\n",
        "    loss.backward()\n",
        "    optm.step()\n",
        "    av_loss += loss.item()\n",
        "\n",
        "\n",
        "  print(f'average loss per batch in {i}th epoch is {av_loss/len(train)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT05kz6klIKo",
        "outputId": "e00c5fb3-672e-4072-c02e-1651749a4ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mycnn(\n",
              "  (filter): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layers): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=3136, out_features=1000, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Dropout(p=0.4, inplace=False)\n",
              "    (5): Linear(in_features=1000, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX5ZLfaukDZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d0aa6f-81b8-43d9-d324-b8fd3de34d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data is 0.889\n"
          ]
        }
      ],
      "source": [
        "\n",
        "total =0\n",
        "corr =0\n",
        "with torch.no_grad():\n",
        "  for batch,batch_label in test:\n",
        "    batch = batch.to(device)\n",
        "    batch_label = batch_label.to(device)\n",
        "    out = cnn(batch)\n",
        "    _,pred = torch.max(out,1)\n",
        "\n",
        "    corr += (pred == batch_label).sum().item()\n",
        "    total += batch.shape[0]\n",
        "print(f'Accuracy on test data is {corr/total}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = draw_graph(cnn, input_size=(1, 1, 28, 28))\n",
        "graph.visual_graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jPpBXvoxpnU9",
        "outputId": "919f8080-7af0-4491-87e5-02e1caacc9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: model Pages: 1 -->\n<svg width=\"181pt\" height=\"864pt\"\n viewBox=\"0.00 0.00 180.72 864.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.72 0.72) rotate(0) translate(4 1196)\">\n<title>model</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1196 247,-1196 247,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"210.5,-1192 32.5,-1192 32.5,-1160 210.5,-1160 210.5,-1192\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"32.5,-1160 32.5,-1192 115.5,-1192 115.5,-1160 32.5,-1160\"/>\n<text text-anchor=\"start\" x=\"37.5\" y=\"-1179\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-1168\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-1160 115.5,-1192 210.5,-1192 210.5,-1160 115.5,-1160\"/>\n<text text-anchor=\"start\" x=\"120.5\" y=\"-1173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1, 28, 28)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"231,-1124 12,-1124 12,-1082 231,-1082 231,-1124\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"12.5,-1082 12.5,-1124 65.5,-1124 65.5,-1082 12.5,-1082\"/>\n<text text-anchor=\"start\" x=\"20.5\" y=\"-1106\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-1095\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-1103 65.5,-1124 124.5,-1124 124.5,-1103 65.5,-1103\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-1111\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-1103 124.5,-1124 231.5,-1124 231.5,-1103 124.5,-1103\"/>\n<text text-anchor=\"start\" x=\"132.5\" y=\"-1111\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-1082 65.5,-1103 124.5,-1103 124.5,-1082 65.5,-1082\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-1090\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-1082 124.5,-1103 231.5,-1103 231.5,-1082 124.5,-1082\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-1090\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-1159.94C121.5,-1152.45 121.5,-1143.12 121.5,-1134.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-1134.16 121.5,-1124.16 118,-1134.16 125,-1134.16\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"231,-1046 12,-1046 12,-1004 231,-1004 231,-1046\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"12.5,-1004 12.5,-1046 65.5,-1046 65.5,-1004 12.5,-1004\"/>\n<text text-anchor=\"start\" x=\"26.5\" y=\"-1028\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-1017\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-1025 65.5,-1046 124.5,-1046 124.5,-1025 65.5,-1025\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-1033\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-1025 124.5,-1046 231.5,-1046 231.5,-1025 124.5,-1025\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-1033\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-1004 65.5,-1025 124.5,-1025 124.5,-1004 65.5,-1004\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-1012\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-1004 124.5,-1025 231.5,-1025 231.5,-1004 124.5,-1004\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-1012\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-1081.63C121.5,-1073.82 121.5,-1064.73 121.5,-1056.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-1056.16 121.5,-1046.16 118,-1056.16 125,-1056.16\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"243,-968 0,-968 0,-926 243,-926 243,-968\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-926 0.5,-968 77.5,-968 77.5,-926 0.5,-926\"/>\n<text text-anchor=\"start\" x=\"5.5\" y=\"-950\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-939\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-947 77.5,-968 136.5,-968 136.5,-947 77.5,-947\"/>\n<text text-anchor=\"start\" x=\"88.5\" y=\"-955\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"136.5,-947 136.5,-968 243.5,-968 243.5,-947 136.5,-947\"/>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-955\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-926 77.5,-947 136.5,-947 136.5,-926 77.5,-926\"/>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-934\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"136.5,-926 136.5,-947 243.5,-947 243.5,-926 136.5,-926\"/>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-934\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-1003.63C121.5,-995.82 121.5,-986.73 121.5,-978.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-978.16 121.5,-968.16 118,-978.16 125,-978.16\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"237,-890 6,-890 6,-848 237,-848 237,-890\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"6.5,-848 6.5,-890 71.5,-890 71.5,-848 6.5,-848\"/>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-872\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool2d</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-861\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-869 71.5,-890 130.5,-890 130.5,-869 71.5,-869\"/>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-877\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,-869 130.5,-890 237.5,-890 237.5,-869 130.5,-869\"/>\n<text text-anchor=\"start\" x=\"135.5\" y=\"-877\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 28, 28) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-848 71.5,-869 130.5,-869 130.5,-848 71.5,-848\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-856\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,-848 130.5,-869 237.5,-869 237.5,-848 130.5,-848\"/>\n<text text-anchor=\"start\" x=\"135.5\" y=\"-856\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 14, 14) </text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-925.63C121.5,-917.82 121.5,-908.73 121.5,-900.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-900.16 121.5,-890.16 118,-900.16 125,-900.16\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"231,-812 12,-812 12,-770 231,-770 231,-812\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"12.5,-770 12.5,-812 65.5,-812 65.5,-770 12.5,-770\"/>\n<text text-anchor=\"start\" x=\"20.5\" y=\"-794\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-783\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-791 65.5,-812 124.5,-812 124.5,-791 65.5,-791\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-791 124.5,-812 231.5,-812 231.5,-791 124.5,-791\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-799\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-770 65.5,-791 124.5,-791 124.5,-770 65.5,-770\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-770 124.5,-791 231.5,-791 231.5,-770 124.5,-770\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-778\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 14, 14) </text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-847.63C121.5,-839.82 121.5,-830.73 121.5,-822.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-822.16 121.5,-812.16 118,-822.16 125,-822.16\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"231,-734 12,-734 12,-692 231,-692 231,-734\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"12.5,-692 12.5,-734 65.5,-734 65.5,-692 12.5,-692\"/>\n<text text-anchor=\"start\" x=\"26.5\" y=\"-716\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-713 65.5,-734 124.5,-734 124.5,-713 65.5,-713\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-713 124.5,-734 231.5,-734 231.5,-713 124.5,-713\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-721\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"65.5,-692 65.5,-713 124.5,-713 124.5,-692 65.5,-692\"/>\n<text text-anchor=\"start\" x=\"70.5\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"124.5,-692 124.5,-713 231.5,-713 231.5,-692 124.5,-692\"/>\n<text text-anchor=\"start\" x=\"129.5\" y=\"-700\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 14, 14) </text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-769.63C121.5,-761.82 121.5,-752.73 121.5,-744.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-744.16 121.5,-734.16 118,-744.16 125,-744.16\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"243,-656 0,-656 0,-614 243,-614 243,-656\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-614 0.5,-656 77.5,-656 77.5,-614 0.5,-614\"/>\n<text text-anchor=\"start\" x=\"5.5\" y=\"-638\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-627\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-635 77.5,-656 136.5,-656 136.5,-635 77.5,-635\"/>\n<text text-anchor=\"start\" x=\"88.5\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"136.5,-635 136.5,-656 243.5,-656 243.5,-635 136.5,-635\"/>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-643\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"77.5,-614 77.5,-635 136.5,-635 136.5,-614 77.5,-614\"/>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"136.5,-614 136.5,-635 243.5,-635 243.5,-614 136.5,-614\"/>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 14, 14) </text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-691.63C121.5,-683.82 121.5,-674.73 121.5,-666.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-666.16 121.5,-656.16 118,-666.16 125,-666.16\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"237,-578 6,-578 6,-536 237,-536 237,-578\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"6.5,-536 6.5,-578 71.5,-578 71.5,-536 6.5,-536\"/>\n<text text-anchor=\"start\" x=\"11.5\" y=\"-560\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool2d</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-549\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-557 71.5,-578 130.5,-578 130.5,-557 71.5,-557\"/>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,-557 130.5,-578 237.5,-578 237.5,-557 130.5,-557\"/>\n<text text-anchor=\"start\" x=\"135.5\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 14, 14) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-536 71.5,-557 130.5,-557 130.5,-536 71.5,-536\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,-536 130.5,-557 237.5,-557 237.5,-536 130.5,-536\"/>\n<text text-anchor=\"start\" x=\"141.5\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 7, 7) </text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-613.63C121.5,-605.82 121.5,-596.73 121.5,-588.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-588.16 121.5,-578.16 118,-588.16 125,-588.16\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"225,-500 18,-500 18,-458 225,-458 225,-500\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"18.5,-458 18.5,-500 71.5,-500 71.5,-458 18.5,-458\"/>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">Flatten</text>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-479 71.5,-500 130.5,-500 130.5,-479 71.5,-479\"/>\n<text text-anchor=\"start\" x=\"82.5\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,-479 130.5,-500 225.5,-500 225.5,-479 130.5,-479\"/>\n<text text-anchor=\"start\" x=\"135.5\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 7, 7) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"71.5,-458 71.5,-479 130.5,-479 130.5,-458 71.5,-458\"/>\n<text text-anchor=\"start\" x=\"76.5\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"130.5,-458 130.5,-479 225.5,-479 225.5,-458 130.5,-458\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3136) </text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-535.63C121.5,-527.82 121.5,-518.73 121.5,-510.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-510.16 121.5,-500.16 118,-510.16 125,-510.16\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"213,-422 30,-422 30,-380 213,-380 213,-422\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"30.5,-380 30.5,-422 83.5,-422 83.5,-380 30.5,-380\"/>\n<text text-anchor=\"start\" x=\"38.5\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-401 83.5,-422 142.5,-422 142.5,-401 83.5,-401\"/>\n<text text-anchor=\"start\" x=\"94.5\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-401 142.5,-422 213.5,-422 213.5,-401 142.5,-401\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3136) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-380 83.5,-401 142.5,-401 142.5,-380 83.5,-380\"/>\n<text text-anchor=\"start\" x=\"88.5\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-380 142.5,-401 213.5,-401 213.5,-380 142.5,-380\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-457.63C121.5,-449.82 121.5,-440.73 121.5,-432.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-432.16 121.5,-422.16 118,-432.16 125,-432.16\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"213,-344 30,-344 30,-302 213,-302 213,-344\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"30.5,-302 30.5,-344 83.5,-344 83.5,-302 30.5,-302\"/>\n<text text-anchor=\"start\" x=\"44.5\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-323 83.5,-344 142.5,-344 142.5,-323 83.5,-323\"/>\n<text text-anchor=\"start\" x=\"94.5\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-323 142.5,-344 213.5,-344 213.5,-323 142.5,-323\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-302 83.5,-323 142.5,-323 142.5,-302 83.5,-302\"/>\n<text text-anchor=\"start\" x=\"88.5\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-302 142.5,-323 213.5,-323 213.5,-302 142.5,-302\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-379.63C121.5,-371.82 121.5,-362.73 121.5,-354.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-354.16 121.5,-344.16 118,-354.16 125,-354.16\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"225,-266 18,-266 18,-224 225,-224 225,-266\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"18.5,-224 18.5,-266 95.5,-266 95.5,-224 18.5,-224\"/>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-248\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm1d</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-237\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"95.5,-245 95.5,-266 154.5,-266 154.5,-245 95.5,-245\"/>\n<text text-anchor=\"start\" x=\"106.5\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"154.5,-245 154.5,-266 225.5,-266 225.5,-245 154.5,-245\"/>\n<text text-anchor=\"start\" x=\"159.5\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"95.5,-224 95.5,-245 154.5,-245 154.5,-224 95.5,-224\"/>\n<text text-anchor=\"start\" x=\"100.5\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"154.5,-224 154.5,-245 225.5,-245 225.5,-224 154.5,-224\"/>\n<text text-anchor=\"start\" x=\"159.5\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-301.63C121.5,-293.82 121.5,-284.73 121.5,-276.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-276.16 121.5,-266.16 118,-276.16 125,-276.16\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"213,-188 30,-188 30,-146 213,-146 213,-188\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"30.5,-146 30.5,-188 83.5,-188 83.5,-146 30.5,-146\"/>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-167 83.5,-188 142.5,-188 142.5,-167 83.5,-167\"/>\n<text text-anchor=\"start\" x=\"94.5\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-167 142.5,-188 213.5,-188 213.5,-167 142.5,-167\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-146 83.5,-167 142.5,-167 142.5,-146 83.5,-146\"/>\n<text text-anchor=\"start\" x=\"88.5\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-146 142.5,-167 213.5,-167 213.5,-146 142.5,-146\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-223.63C121.5,-215.82 121.5,-206.73 121.5,-198.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-198.16 121.5,-188.16 118,-198.16 125,-198.16\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"213,-110 30,-110 30,-68 213,-68 213,-110\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"30.5,-68 30.5,-110 83.5,-110 83.5,-68 30.5,-68\"/>\n<text text-anchor=\"start\" x=\"38.5\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"35.5\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-89 83.5,-110 142.5,-110 142.5,-89 83.5,-89\"/>\n<text text-anchor=\"start\" x=\"94.5\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-89 142.5,-110 213.5,-110 213.5,-89 142.5,-89\"/>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1000) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"83.5,-68 83.5,-89 142.5,-89 142.5,-68 83.5,-68\"/>\n<text text-anchor=\"start\" x=\"88.5\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-68 142.5,-89 213.5,-89 213.5,-68 142.5,-68\"/>\n<text text-anchor=\"start\" x=\"153.5\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 10) </text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-145.63C121.5,-137.82 121.5,-128.73 121.5,-120.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-120.16 121.5,-110.16 118,-120.16 125,-120.16\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"192.5,-32 50.5,-32 50.5,0 192.5,0 192.5,-32\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"50.5,0 50.5,-32 139.5,-32 139.5,0 50.5,0\"/>\n<text text-anchor=\"start\" x=\"55.5\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"73.5\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"139.5,0 139.5,-32 192.5,-32 192.5,0 139.5,0\"/>\n<text text-anchor=\"start\" x=\"144.5\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 10)</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.5,-67.84C121.5,-59.89 121.5,-50.66 121.5,-42.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125,-42.24 121.5,-32.24 118,-42.24 125,-42.24\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7a9045ff9790>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Try with Pretrained Models"
      ],
      "metadata": {
        "id": "Ha_TaO11l4Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "ughD-en7lRAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_f = model.fc.in_features\n",
        "model.fc = nn.Linear(in_f,10)"
      ],
      "metadata": {
        "id": "5Q_hTKKGrogQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "MQt9LLLdnGGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "Fppve00vnWF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=45),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485 , 0.456, 0.406] , std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485 , 0.456, 0.406] , std=[0.229,0.224,0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "ZmBZ-G_ooVUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CusData2(Dataset):\n",
        "  def __init__(self,X,y,transforms):\n",
        "    self.features = X\n",
        "    self.labels = y\n",
        "    self.transform = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "    pass\n",
        "  def __getitem__(self, index):\n",
        "    img = self.features[index].reshape(28,28)\n",
        "    img = img.astype(np.uint8)\n",
        "    img = np.stack([img]*3,axis=-1)\n",
        "    img = Image.fromarray(img)\n",
        "    img = self.transform(img)\n",
        "\n",
        "\n",
        "    return img , torch.tensor(self.labels[index],dtype=torch.long)"
      ],
      "metadata": {
        "id": "9JfifgxMnWhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = d.drop(columns='label').to_numpy()\n",
        "y = d['label'].to_numpy()"
      ],
      "metadata": {
        "id": "iEZC5vBfnvJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,shuffle=True)"
      ],
      "metadata": {
        "id": "SfqnC_bnn2YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CusData2(X_train,Y_train,transformer)\n",
        "test_data = CusData2(X_test,Y_test,test_transform)"
      ],
      "metadata": {
        "id": "RCKJxpIGn_sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = DataLoader(train_data,batch_size=64,shuffle=True,pin_memory=True)\n",
        "test = DataLoader(test_data,batch_size=64,shuffle=False,pin_memory=True)"
      ],
      "metadata": {
        "id": "tIR8FuEiod_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4ja0vQWqh2m",
        "outputId": "5dbfe65e-48b7-41a7-b707-4eec2a83cc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  av_los = 0\n",
        "  model.train()\n",
        "  for batch,batch_label in train:\n",
        "    batch = batch.to(device)\n",
        "    batch_label = batch_label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(batch)\n",
        "    loss = criterion(out,batch_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    av_los += loss.item()\n",
        "  print(f'Average on per batch in {i}th iteration is {av_los/len(train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e8QrYc1DqipL",
        "outputId": "2b7de6a8-54c4-4cbf-fdf2-22dd766000f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average on per batch in 0th iteration is 0.8170789248943329\n",
            "Average on per batch in 1th iteration is 0.7691787838935852\n",
            "Average on per batch in 2th iteration is 0.723746054649353\n",
            "Average on per batch in 3th iteration is 0.7042241015434265\n",
            "Average on per batch in 4th iteration is 0.6893605101108551\n",
            "Average on per batch in 5th iteration is 0.6908097214698792\n",
            "Average on per batch in 6th iteration is 0.68559557056427\n",
            "Average on per batch in 7th iteration is 0.669533177614212\n",
            "Average on per batch in 8th iteration is 0.6555738167762757\n",
            "Average on per batch in 9th iteration is 0.6481566565036774\n",
            "Average on per batch in 10th iteration is 0.6539863455295563\n",
            "Average on per batch in 11th iteration is 0.6381162848472596\n",
            "Average on per batch in 12th iteration is 0.6348877539634704\n",
            "Average on per batch in 13th iteration is 0.6347021975517273\n",
            "Average on per batch in 14th iteration is 0.6166372270584106\n",
            "Average on per batch in 15th iteration is 0.6307974314689636\n",
            "Average on per batch in 16th iteration is 0.612052262544632\n",
            "Average on per batch in 17th iteration is 0.6210341296195984\n",
            "Average on per batch in 18th iteration is 0.6228987071514129\n",
            "Average on per batch in 19th iteration is 0.604168683052063\n",
            "Average on per batch in 20th iteration is 0.6260402634143829\n",
            "Average on per batch in 21th iteration is 0.6008568766117096\n",
            "Average on per batch in 22th iteration is 0.5961709325313568\n",
            "Average on per batch in 23th iteration is 0.6041335554122925\n",
            "Average on per batch in 24th iteration is 0.6048411684036255\n",
            "Average on per batch in 25th iteration is 0.6130797679424286\n",
            "Average on per batch in 26th iteration is 0.594570684671402\n",
            "Average on per batch in 27th iteration is 0.5968176331520081\n",
            "Average on per batch in 28th iteration is 0.5889438683986664\n",
            "Average on per batch in 29th iteration is 0.591432418346405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "z75wyif2s4BC",
        "outputId": "3d73cede-e888-4552-e990-64d24520f8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2029845769.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total =0\n",
        "corr =0\n",
        "with torch.no_grad():\n",
        "  for batch,batch_label in test:\n",
        "    batch = batch.to(device)\n",
        "    batch_label = batch_label.to(device)\n",
        "    out = model(batch)\n",
        "    _,pred = torch.max(out,1)\n",
        "\n",
        "    corr += (pred == batch_label).sum().item()\n",
        "    total += batch.shape[0]\n",
        "print(f'Accuracy on test data is {corr/total}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPYDPyk62vsH",
        "outputId": "776cce9b-b71b-4f85-aa13-eb054903df20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data is 0.746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model\": cnn.state_dict(),\n",
        "    \"optimizer\": optimizer.state_dict(),\n",
        "    \"epoch\": epoch\n",
        "}, \"checkpoint.pth\")"
      ],
      "metadata": {
        "id": "-PwKUkjo5usC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5JnvKla5wll"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}