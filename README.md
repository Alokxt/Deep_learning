# ğŸ§  Deep Learning From Scratch & Projects

This repository contains my **deep learning learning journey**, where I implement:

- ğŸ”¹ Deep learning concepts **from scratch using NumPy & Pytorch**
- ğŸ”¹ Core algorithms and training loops
- ğŸ”¹ Small deep learning projects
- ğŸ”¹ Experiments with activation functions, loss functions, and optimizers


The main goal of this repository is to **understand deep learning at a low level**.

---

## ğŸ“Œ What This Repository Includes

### âœ… 1. Neural Networks From Scratch
Implementation of:
- Forward Propagation
- Backpropagation
- Weight & Bias Updates
- Gradient Descent
 
### âœ… 2. Backpropagation Optimization Algorithms (From Scratch in PyTorch)
Learned Advanced Optimization Techniques and implemented with Pytorch.
- Gradient Descent (GD)
- Momentum-Based Gradient Descent
- Nesterov Accelerated Gradient (NAG / NGD)
- RMSProp
- Adagrad
- AdaDelta
- Adam
- AdamW

These implementations focus on:
- How gradients are updated internally  
- How momentum and velocity work  
- Moving averages & bias correction  
- Weight decay & stability  
- Convergence behavior  


### âœ… Mini Deep Learning Projects
  - *Fashion-Mnist classification*
(Projects will be added continuously âœ…)

---

### âœ… Experimentation & Learning
This repo also contains:
- Architecture experiments
- Debugging backprop
- Gradient checking
- Accuracy and evaluation metrics

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python
- **Core Library:** NumPy, PyTorch / TensorFlow


---

